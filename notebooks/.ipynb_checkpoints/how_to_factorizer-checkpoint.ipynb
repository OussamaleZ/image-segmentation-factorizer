{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4185120c-a86b-4a02-84c7-8da04aa45956",
   "metadata": {},
   "source": [
    "The following notebook is based on: https://github.com/pashtari/factorizer-isles22/blob/master/get_started.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ad9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c286c2df-d770-40b1-aee7-4a6129e521e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6363045-5309-4cb0-b988-29f080f03a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/pashtari/factorizer.git@0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6ff387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import factorizer as ft\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import pytorch_lightning as pl\n",
    "from monai import transforms\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "import factorizer as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5848aa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n"
     ]
    }
   ],
   "source": [
    "print(12*12*12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91900275-988d-43d7-95fb-693e6eb64c87",
   "metadata": {},
   "source": [
    "## Check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d069829",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m swin_factorizer = \u001b[43mft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspatial_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLayerNorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSWMatricize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhead_dim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReLU\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mNMF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_iters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muniform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhals\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m x = torch.rand((\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m     23\u001b[39m y = swin_factorizer(x)\n",
      "\u001b[31mTypeError\u001b[39m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# swin_factorizer = ft.factorizer(\n",
    "#     in_channels=4,\n",
    "#     out_channels=3,\n",
    "#     spatial_size=(8, 8, 8),\n",
    "#     encoder_depth=(1, 1, 1),\n",
    "#     encoder_width=(2, 2, 2),\n",
    "#     strides=(1, 2, 2),\n",
    "#     decoder_depth=(1, 1, 1, 1),\n",
    "#     norm=ft.LayerNorm,\n",
    "#     reshape=(ft.SWMatricize, {'head_dim': 2, 'patch_size': 2}),\n",
    "#     act=nn.ReLU,\n",
    "#     factorize=ft.NMF,\n",
    "#     rank=1,\n",
    "#     num_iters=5,\n",
    "#     init=\"uniform\",\n",
    "#     solver=\"hals\",\n",
    "#     mlp_ratio=2,\n",
    "#     dropout=0.1\n",
    "# )\n",
    "\n",
    "# x = torch.rand((1, 4, 8, 8, 8))\n",
    "\n",
    "# y = swin_factorizer(x)\n",
    "# print(\"Output shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swin_factorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab5db5-b9b2-4d1a-b9f6-fbce70d759ff",
   "metadata": {},
   "source": [
    "## Check image shape and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d485fe2-e96d-4705-8f3d-e9ca044b423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.path.exists(\"/Data/\"))\n",
    "print(os.path.exists(\"/Data/data/isles/sub-strokecase0001/ses-0001/anat/sub-strokecase0001_ses-0001_flair_registered.nii.gz\"))\n",
    "print(os.path.exists(\"Data/data/isles/sub-strokecase0100/ses-0001/dwi/sub-strokecase0100_ses-0001_dwi.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123b900-cd6c-4ef4-b3b1-db74a24dc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path and\n",
    "dataset_dir = \"/Data/data/isles\"\n",
    "\n",
    "# set patient ID and images path\n",
    "id_ = \"sub-strokecase0001\"\n",
    "dwi_path = f\"{dataset_dir}/{id_}/ses-0001/dwi/{id_}_ses-0001_dwi.nii.gz\"\n",
    "adc_path = f\"{dataset_dir}/{id_}/ses-0001/dwi/{id_}_ses-0001_adc.nii.gz\"\n",
    "\n",
    "msk_path = f\"{dataset_dir}/derivatives/{id_}/ses-0001/{id_}_ses-0001_msk.nii.gz\"\n",
    "\n",
    "# make data dictionary\n",
    "data = {\n",
    "    \"image\": [dwi_path, adc_path],\n",
    "    \"mask\": msk_path,\n",
    "}\n",
    "\n",
    "load_image = transforms.LoadImaged(\n",
    "    [\"image\", \"mask\"],\n",
    "    ensure_channel_first=True,\n",
    "    allow_missing_keys=True,\n",
    ")\n",
    "\n",
    "# load image data\n",
    "data = load_image(data)\n",
    "print(f\"image shape: {data['image'].shape}\")\n",
    "print(f\"mask shape: {data['mask'].shape}\")\n",
    "\n",
    "\n",
    "dwi_image = data[\"image\"][0]\n",
    "adc_image = data[\"image\"][1]\n",
    "msk_image = data[\"mask\"][0]\n",
    "\n",
    "# pick a slice with the largest lesion volume for visualization\n",
    "slc = msk_image.sum((0, 1)).argmax()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, dpi=200)\n",
    "# visulize DWI image\n",
    "ax[0].imshow(dwi_image[:, :, slc], cmap=\"gray\", origin=\"lower\")\n",
    "ax[0].set_title(\"DWI\")\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "# visulize ADC image\n",
    "ax[1].imshow(adc_image[:, :, slc], cmap=\"gray\", origin=\"lower\")\n",
    "ax[1].set_title(\"ADC\")\n",
    "ax[1].set_axis_off()\n",
    "\n",
    "# visulize mask\n",
    "ax[2].imshow(dwi_image[:, :, slc], \"gray\", origin=\"lower\")\n",
    "masked = np.ma.masked_where(msk_image[:, :, slc] == 0, dwi_image[:, :, slc])\n",
    "ax[2].imshow(masked, ListedColormap([\"red\"]), alpha=0.9, origin=\"lower\")\n",
    "ax[2].set_title(\"Ground Truth\")\n",
    "ax[2].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7daa9-012a-4835-ab01-4315227df894",
   "metadata": {},
   "source": [
    "## Setup transforms for training and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b349a-bf33-497d-b6b3-cd1b6be5a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    train_transform = [\n",
    "        ft.ReadImaged([\"image\", \"label\"], ensure_channel_first=True),\n",
    "        transforms.SqueezeDimd(\"image\", dim=1),\n",
    "        transforms.CropForegroundd([\"image\", \"label\"], source_key=\"image\"),\n",
    "        transforms.NormalizeIntensityd(\"image\", nonzero=True, channel_wise=True),\n",
    "        transforms.Spacingd(\n",
    "            [\"image\", \"label\"],\n",
    "            pixdim=(2.0, 2.0, 2.0),\n",
    "            mode=(\"bilinear\", \"bilinear\"),\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            [\"image\", \"label\"], roi_size=(64, 64, 64), random_size=False\n",
    "        ),\n",
    "        transforms.RandAffined(\n",
    "            [\"image\", \"label\"],\n",
    "            prob=0.15,\n",
    "            spatial_size=(64, 64, 64),\n",
    "            rotate_range=[30 * np.pi / 180] * 3,\n",
    "            scale_range=[0.3] * 3,\n",
    "            mode=(\"bilinear\", \"bilinear\"),\n",
    "            as_tensor_output=False,\n",
    "        ),\n",
    "        transforms.RandFlipd([\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        transforms.RandFlipd([\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        transforms.RandFlipd([\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        transforms.RandGaussianNoised(\"image\", prob=0.15, std=0.1),\n",
    "        transforms.RandGaussianSmoothd(\n",
    "            \"image\",\n",
    "            prob=0.15,\n",
    "            sigma_x=(0.5, 1.5),\n",
    "            sigma_y=(0.5, 1.5),\n",
    "            sigma_z=(0.5, 1.5),\n",
    "        ),\n",
    "        transforms.RandScaleIntensityd(\"image\", prob=0.15, factors=0.3),\n",
    "        transforms.RandShiftIntensityd(\"image\", prob=0.15, offsets=0.1),\n",
    "        transforms.RandAdjustContrastd(\"image\", prob=0.15, gamma=(0.7, 1.5)),\n",
    "        transforms.AsDiscreted(\"label\", threshold=0.5),\n",
    "        transforms.ToTensord([\"image\", \"label\"]),\n",
    "    ]\n",
    "    train_transform = transforms.Compose(train_transform)\n",
    "    return train_transform\n",
    "\n",
    "\n",
    "def get_val_transform():\n",
    "    val_transform = [\n",
    "        ft.ReadImaged(\n",
    "            [\"image\", \"label\"], ensure_channel_first=True, allow_missing_keys=True\n",
    "        ),\n",
    "        transforms.SqueezeDimd(\"image\", dim=1),\n",
    "        transforms.NormalizeIntensityd(\"image\", nonzero=True, channel_wise=True),\n",
    "        transforms.ToTensord([\"image\", \"label\"], allow_missing_keys=True),\n",
    "    ]\n",
    "    val_transform = transforms.Compose(val_transform)\n",
    "    return val_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff70f31-e0f5-4202-ba5a-f19c3bff644c",
   "metadata": {},
   "source": [
    "## Registry & Read config function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a1dce-a704-4607-a2fe-ad501ddfb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from torch import nn, optim\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "import factorizer as ft\n",
    "\n",
    "def lambda_constructor(loader, node):\n",
    "    lambda_expr = \"lambda \" + loader.construct_scalar(node)\n",
    "    return eval(lambda_expr)\n",
    "\n",
    "\n",
    "def get_constructor(obj):\n",
    "    \"\"\"Get constructor for an object.\"\"\"\n",
    "\n",
    "    def constructor(loader, node):\n",
    "        if isinstance(node, yaml.nodes.ScalarNode):\n",
    "            if node.value:\n",
    "                out = obj(loader.construct_scalar(node))\n",
    "            else:\n",
    "                out = obj\n",
    "        elif isinstance(node, yaml.nodes.SequenceNode):\n",
    "            out = obj(*loader.construct_sequence(node, deep=True))\n",
    "        elif isinstance(node, yaml.nodes.MappingNode):\n",
    "            out = obj(**loader.construct_mapping(node, deep=True))\n",
    "\n",
    "        return out\n",
    "\n",
    "    return constructor\n",
    "\n",
    "\n",
    "def add_attributes(obj, prefix=\"\"):\n",
    "    for attr_name in dir(obj):\n",
    "        if not attr_name.startswith(\"_\"):\n",
    "            Loader.add_constructor(\n",
    "                f\"!{prefix}{attr_name}\",\n",
    "                get_constructor(getattr(obj, attr_name)),\n",
    "            )\n",
    "\n",
    "\n",
    "Loader = yaml.SafeLoader\n",
    "\n",
    "\n",
    "# general\n",
    "Loader.add_constructor(\"!eval\", get_constructor(eval))\n",
    "Loader.add_constructor(\"!lambda\", lambda_constructor)\n",
    "\n",
    "\n",
    "# pytorch\n",
    "add_attributes(nn, \"nn.\")\n",
    "add_attributes(optim, \"optim.\")\n",
    "\n",
    "\n",
    "# pytorch lightning\n",
    "add_attributes(pl.callbacks, \"pl.\")\n",
    "add_attributes(pl.loggers, \"pl.\")\n",
    "\n",
    "\n",
    "# monai\n",
    "add_attributes(monai.losses, \"monai.\")\n",
    "add_attributes(monai.networks.nets, \"monai.\")\n",
    "\n",
    "\n",
    "# factorizer\n",
    "add_attributes(ft, \"ft.\")\n",
    "\n",
    "\n",
    "def read_config(path, loader=Loader):\n",
    "    with open(path, \"rb\") as file:\n",
    "        config = yaml.load(file, loader)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cda03-8b1d-4faa-9556-885d5ec3b7d6",
   "metadata": {},
   "source": [
    "## Quick checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754be30-a05b-4a81-89a1-be1df55af35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.ISLESDataModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e3e34-c14b-4bf0-8afa-a281b40b67ef",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877b4fa-a16d-46ea-a9df-3437c9cf30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from argparse import ArgumentParser, Namespace\n",
    "\n",
    "# get config\n",
    "# parser = ArgumentParser(description=\"\"\"Train the model.\"\"\", add_help=False)\n",
    "# parser.add_argument(\"--config\", type=str, required=True)\n",
    "# args = parser.parse_args()\n",
    "path_config = \"/users/eleves-a/2022/oussama.zouhry/factorizer-project/image-segmentation-factorizer/factorizer/configs/isles2022-dwi&adc/config_isles2022-dwi&adc_fold0_swin-factorizer.yaml\"\n",
    "config = read_config(path_config)\n",
    "\n",
    "# data\n",
    "dm = config[\"data\"]\n",
    "\n",
    "# init model\n",
    "task_cls, task_params = config[\"task\"]\n",
    "if \"checkpoint_path\" in task_params:\n",
    "    model = task_cls.load_from_checkpoint(strict=False, **task_params)\n",
    "else:\n",
    "    model = task_cls(**task_params)\n",
    "\n",
    "# init trainer\n",
    "trainer = Trainer(**config[\"training\"])\n",
    "\n",
    "# fit model\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6fb81-b79a-4a5c-9a26-8b7f2633e85c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
