{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c17f867",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236ca114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Data/factorizer-env3.9/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import factorizer as ft\n",
    "from monai import transforms\n",
    "from tqdm import tqdm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74595af1",
   "metadata": {},
   "source": [
    "### Registry definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305263b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from torch import nn, optim\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "import factorizer as ft\n",
    "\n",
    "\n",
    "def lambda_constructor(loader, node):\n",
    "    lambda_expr = \"lambda \" + loader.construct_scalar(node)\n",
    "    return eval(lambda_expr)\n",
    "\n",
    "\n",
    "def get_constructor(obj):\n",
    "    \"\"\"Get constructor for an object.\"\"\"\n",
    "\n",
    "    def constructor(loader, node):\n",
    "        if isinstance(node, yaml.nodes.ScalarNode):\n",
    "            if node.value:\n",
    "                out = obj(loader.construct_scalar(node))\n",
    "            else:\n",
    "                out = obj\n",
    "        elif isinstance(node, yaml.nodes.SequenceNode):\n",
    "            out = obj(*loader.construct_sequence(node, deep=True))\n",
    "        elif isinstance(node, yaml.nodes.MappingNode):\n",
    "            out = obj(**loader.construct_mapping(node, deep=True))\n",
    "\n",
    "        return out\n",
    "\n",
    "    return constructor\n",
    "\n",
    "\n",
    "def add_attributes(obj, prefix=\"\"):\n",
    "    for attr_name in dir(obj):\n",
    "        if not attr_name.startswith(\"_\"):\n",
    "            Loader.add_constructor(\n",
    "                f\"!{prefix}{attr_name}\",\n",
    "                get_constructor(getattr(obj, attr_name)),\n",
    "            )\n",
    "\n",
    "\n",
    "Loader = yaml.SafeLoader\n",
    "\n",
    "\n",
    "# general\n",
    "Loader.add_constructor(\"!eval\", get_constructor(eval))\n",
    "Loader.add_constructor(\"!lambda\", lambda_constructor)\n",
    "\n",
    "\n",
    "# pytorch\n",
    "add_attributes(nn, \"nn.\")\n",
    "add_attributes(optim, \"optim.\")\n",
    "\n",
    "\n",
    "# pytorch lightning\n",
    "add_attributes(pl.callbacks, \"pl.\")\n",
    "add_attributes(pl.loggers, \"pl.\")\n",
    "\n",
    "\n",
    "# monai\n",
    "add_attributes(monai.losses, \"monai.\")\n",
    "add_attributes(monai.networks.nets, \"monai.\")\n",
    "\n",
    "\n",
    "# factorizer\n",
    "add_attributes(ft, \"ft.\")\n",
    "\n",
    "\n",
    "def read_config(path, loader=Loader):\n",
    "    with open(path, \"rb\") as file:\n",
    "        config = yaml.load(file, loader)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c2be4",
   "metadata": {},
   "source": [
    "### Data module and inferer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8f4042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `wandb.require('service')` is a no-op as it is now the default behavior.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moz2102\u001b[0m (\u001b[33mimage-segmentation-factorizer\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Data/logs/isles2022-dwi&adc/fold0/wandb/run-20251130_150101-19s1laye</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/image-segmentation-factorizer/image-segmentation-factorizer/runs/19s1laye' target=\"_blank\">swin-factorizer-fold0-isles</a></strong> to <a href='https://wandb.ai/image-segmentation-factorizer/image-segmentation-factorizer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/image-segmentation-factorizer/image-segmentation-factorizer' target=\"_blank\">https://wandb.ai/image-segmentation-factorizer/image-segmentation-factorizer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/image-segmentation-factorizer/image-segmentation-factorizer/runs/19s1laye' target=\"_blank\">https://wandb.ai/image-segmentation-factorizer/image-segmentation-factorizer/runs/19s1laye</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██| 4/4 [00:00<00:00, 24.39it/s]\n",
      "Loading dataset: 100%|██| 4/4 [00:00<00:00, 37.25it/s]\n"
     ]
    }
   ],
   "source": [
    "config = read_config(\"../configs/isles2022-dwi&adc/config_isles2022-dwi&adc_fold0_swin-factorizer.yaml\")\n",
    "dm = config[\"data\"]\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e537e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferer = ft.ISLESInferer(\n",
    "    spacing=[2.0, 2.0, 2.0],\n",
    "    spatial_size=[64, 64, 64],\n",
    "    overlap=0.5,\n",
    "    post=\"class\",\n",
    "    mode = \"constant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1cd393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "post_pred = AsDiscrete(threshold=0.5)\n",
    "post_label = AsDiscrete(threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77713a0c",
   "metadata": {},
   "source": [
    "### Inference given a checkpoint path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef6842a-daf4-4e5d-a982-1bd4e27e349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score_chkpt(checkpoint_path):\n",
    "    model = ft.SemanticSegmentation.load_from_checkpoint(checkpoint_path, inferer=inferer).to(device)\n",
    "    print(model.device)\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dm.val_dataloader()):\n",
    "            batch['input'] = batch['input'].to(device)\n",
    "            batch['target'] = batch['target'].to(device)\n",
    "            pred = model.inferer.get_postprocessed(batch, model)\n",
    "            \n",
    "            dice_metric(\n",
    "                y_pred=post_pred(pred['input']),\n",
    "                y=post_label(batch['target']),\n",
    "            )\n",
    "            \n",
    "    dice_scores = dice_metric.aggregate(reduction=\"mean_batch\").cpu().numpy()\n",
    "    dice_metric.reset()\n",
    "\n",
    "    return dice_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acc280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu116\n",
      "11.6\n",
      "True\n",
      "NVIDIA RTX A4000\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_capability(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c99f02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, coherent with what we have in wandb.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_root = Path(\"/Data/logs/isles2022-dwi&adc/fold0/image-segmentation-factorizer/51ij4wr5/checkpoints/epoch=999-step=100000.ckpt\")\n",
    "# print(\"Dataset Dice (mean):\", dice_score_chkpt(checkpoint_root))\n",
    "print(\"Nice, coherent with what we have in wandb.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4295b2",
   "metadata": {},
   "source": [
    "### Use a new rank in inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78ae439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epoch=999-step=100000.ckpt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"/Data/logs/isles2022-dwi&adc/fold0/image-segmentation-factorizer/51ij4wr5/checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c987f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ft.SemanticSegmentation.load_from_checkpoint(checkpoint_root, inferer=inferer).to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f586acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score_chkpt(checkpoint_path, rank = 1):\n",
    "    model = ft.SemanticSegmentation.load_from_checkpoint(checkpoint_path, inferer=inferer).to(device)\n",
    "    # change the rank in the model\n",
    "    for name, module in model.net.named_modules():\n",
    "        if isinstance(module, ft.FactorizerSubblock):\n",
    "            module.factorize.update_rank(rank = rank)\n",
    "\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dm.val_dataloader()):\n",
    "            batch['input'] = batch['input'].to(device)\n",
    "            batch['target'] = batch['target'].to(device)\n",
    "            pred = model.inferer.get_postprocessed(batch, model)\n",
    "            \n",
    "            dice_metric(\n",
    "                y_pred=post_pred(pred['input']),\n",
    "                y=post_label(batch['target']),\n",
    "            )\n",
    "            \n",
    "    dice_scores = dice_metric.aggregate(reduction=\"mean_batch\").cpu().numpy()\n",
    "    dice_metric.reset()\n",
    "\n",
    "    return dice_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc2121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|█▍                | 4/50 [00:21<04:06,  5.36s/it]"
     ]
    }
   ],
   "source": [
    "for rank in [2, 4, 8, 16, 32]:\n",
    "    print(\"Dataset Dice (mean) for rank =\", rank, \"is:\", dice_score_chkpt(checkpoint_root, rank = rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3731f00-8527-4d8c-bf59-f8208e17961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ed949",
   "metadata": {},
   "source": [
    "### Trial & Error part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c7eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.net\n",
    "print(\"The attributes of model.net are: \", dir(model.net))\n",
    "print(\"The named modules of model.net are: \", model.net.named_modules())\n",
    "\n",
    "print(\"The encoder at model net is:\", model.net.encoder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b0d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The first encoderblock of the encoder is:\", model.net.encoder.blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first block of the first encoderblock of the encoder is:\", model.net.encoder.blocks[0].blocks[0].blocks.nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ecfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted this info from config\n",
    "#   factorize: !ft.NMF\n",
    "#   rank: 1\n",
    "#   num_iters: 5\n",
    "#   num_grad_steps: null\n",
    "#   init: uniform\n",
    "#   solver: hals\n",
    "#   dropout: 0.1\n",
    "ranks = []\n",
    "for name, module in model.net.named_modules():\n",
    "    if isinstance(module, ft.FactorizerSubblock):\n",
    "        module.factorize.update_rank(rank = 10)\n",
    "        print()\n",
    "\n",
    "        ranks.append(module.factorize.rank)\n",
    "        \n",
    "print(\"Factorizer ranks:\", ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
