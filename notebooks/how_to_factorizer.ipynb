{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4185120c-a86b-4a02-84c7-8da04aa45956",
   "metadata": {},
   "source": [
    "The following notebook is based on: https://github.com/pashtari/factorizer-isles22/blob/master/get_started.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ad9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c286c2df-d770-40b1-aee7-4a6129e521e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6363045-5309-4cb0-b988-29f080f03a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/pashtari/factorizer.git@0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6ff387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import factorizer as ft\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import pytorch_lightning as pl\n",
    "from monai import transforms\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5848aa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n"
     ]
    }
   ],
   "source": [
    "print(12*12*12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91900275-988d-43d7-95fb-693e6eb64c87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d069829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swin_factorizer = ft.factorizer(\n",
    "#     in_channels=4,\n",
    "#     out_channels=3,\n",
    "#     spatial_size=(8, 8, 8),\n",
    "#     encoder_depth=(1, 1, 1),\n",
    "#     encoder_width=(2, 2, 2),\n",
    "#     strides=(1, 2, 2),\n",
    "#     decoder_depth=(1, 1, 1, 1),\n",
    "#     norm=ft.LayerNorm,\n",
    "#     reshape=(ft.SWMatricize, {'head_dim': 2, 'patch_size': 2}),\n",
    "#     act=nn.ReLU,\n",
    "#     factorize=ft.NMF,\n",
    "#     rank=1,\n",
    "#     num_iters=5,\n",
    "#     init=\"uniform\",\n",
    "#     solver=\"hals\",\n",
    "#     mlp_ratio=2,\n",
    "#     dropout=0.1\n",
    "# )\n",
    "\n",
    "# x = torch.rand((1, 4, 8, 8, 8))\n",
    "\n",
    "# y = swin_factorizer(x)\n",
    "# print(\"Output shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f1644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(swin_factorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab5db5-b9b2-4d1a-b9f6-fbce70d759ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check image shape and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d485fe2-e96d-4705-8f3d-e9ca044b423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"/Data/\"))\n",
    "print(os.path.exists(\"/Data/data/isles/sub-strokecase0001/ses-0001/anat/sub-strokecase0001_ses-0001_flair_registered.nii.gz\"))\n",
    "print(os.path.exists(\"Data/data/isles/sub-strokecase0100/ses-0001/dwi/sub-strokecase0100_ses-0001_dwi.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9123b900-cd6c-4ef4-b3b1-db74a24dc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set data path and\n",
    "# dataset_dir = \"/Data/data/isles\"\n",
    "\n",
    "# # set patient ID and images path\n",
    "# id_ = \"sub-strokecase0001\"\n",
    "# dwi_path = f\"{dataset_dir}/{id_}/ses-0001/dwi/{id_}_ses-0001_dwi.nii.gz\"\n",
    "# adc_path = f\"{dataset_dir}/{id_}/ses-0001/dwi/{id_}_ses-0001_adc.nii.gz\"\n",
    "\n",
    "# msk_path = f\"{dataset_dir}/derivatives/{id_}/ses-0001/{id_}_ses-0001_msk.nii.gz\"\n",
    "\n",
    "# # make data dictionary\n",
    "# data = {\n",
    "#     \"image\": [dwi_path, adc_path],\n",
    "#     \"mask\": msk_path,\n",
    "# }\n",
    "\n",
    "# load_image = transforms.LoadImaged(\n",
    "#     [\"image\", \"mask\"],\n",
    "#     ensure_channel_first=True,\n",
    "#     allow_missing_keys=True,\n",
    "# )\n",
    "\n",
    "# # load image data\n",
    "# data = load_image(data)\n",
    "# print(f\"image shape: {data['image'].shape}\")\n",
    "# print(f\"mask shape: {data['mask'].shape}\")\n",
    "\n",
    "\n",
    "# dwi_image = data[\"image\"][0]\n",
    "# adc_image = data[\"image\"][1]\n",
    "# msk_image = data[\"mask\"][0]\n",
    "\n",
    "# # pick a slice with the largest lesion volume for visualization\n",
    "# slc = msk_image.sum((0, 1)).argmax()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 3, dpi=200)\n",
    "# # visulize DWI image\n",
    "# ax[0].imshow(dwi_image[:, :, slc], cmap=\"gray\", origin=\"lower\")\n",
    "# ax[0].set_title(\"DWI\")\n",
    "# ax[0].set_axis_off()\n",
    "\n",
    "# # visulize ADC image\n",
    "# ax[1].imshow(adc_image[:, :, slc], cmap=\"gray\", origin=\"lower\")\n",
    "# ax[1].set_title(\"ADC\")\n",
    "# ax[1].set_axis_off()\n",
    "\n",
    "# # visulize mask\n",
    "# ax[2].imshow(dwi_image[:, :, slc], \"gray\", origin=\"lower\")\n",
    "# masked = np.ma.masked_where(msk_image[:, :, slc] == 0, dwi_image[:, :, slc])\n",
    "# ax[2].imshow(masked, ListedColormap([\"red\"]), alpha=0.9, origin=\"lower\")\n",
    "# ax[2].set_title(\"Ground Truth\")\n",
    "# ax[2].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7daa9-012a-4835-ab01-4315227df894",
   "metadata": {},
   "source": [
    "## Setup transforms for training and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed4b1611-6880-492c-a3a8-d66b1975006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Transform,\n",
    "    MapTransform,\n",
    "    LoadImaged,\n",
    "    Identityd,\n",
    "    SaveImaged,\n",
    ")\n",
    "\n",
    "class Renamed(Transform):\n",
    "    def __call__(self, data):\n",
    "        if \"image\" in data:\n",
    "            data[\"input\"] = data.pop(\"image\")\n",
    "\n",
    "        if \"image_transforms\" in data:\n",
    "            data[\"input_transforms\"] = data.pop(\"image_transforms\")\n",
    "\n",
    "        if \"image_meta_dict\" in data:\n",
    "            data[\"input_meta_dict\"] = data.pop(\"image_meta_dict\")\n",
    "\n",
    "        if \"label\" in data:\n",
    "            data[\"target\"] = data.pop(\"label\")\n",
    "\n",
    "        if \"label_transforms\" in data:\n",
    "            data[\"target_transforms\"] = data.pop(\"label_transforms\")\n",
    "\n",
    "        if \"label_meta_dict\" in data:\n",
    "            data[\"target_meta_dict\"] = data.pop(\"label_meta_dict\")\n",
    "\n",
    "        if \"id\" in data:\n",
    "            data[\"input_meta_dict\"][\"filename_or_obj\"] = data[\"id\"]\n",
    "        else:\n",
    "            data[\"id\"] = os.path.basename(\n",
    "                data[\"input_meta_dict\"][\"filename_or_obj\"]\n",
    "            ).split(\".\")[0]\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f29b349a-bf33-497d-b6b3-cd1b6be5a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    train_transform = [\n",
    "        ft.ReadImaged([\"image\", \"label\"], ensure_channel_first=True),\n",
    "        transforms.SqueezeDimd(\"image\", dim=1),\n",
    "        transforms.CropForegroundd([\"image\", \"label\"], source_key=\"image\"),\n",
    "        transforms.NormalizeIntensityd(\"image\", nonzero=True, channel_wise=True),\n",
    "        transforms.Spacingd(\n",
    "            [\"image\", \"label\"],\n",
    "            pixdim=(2.0, 2.0, 2.0),\n",
    "            mode=(\"bilinear\", \"bilinear\"),\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            [\"image\", \"label\"], roi_size=(64, 64, 64), random_size=False\n",
    "        ),\n",
    "        transforms.RandAffined(\n",
    "            [\"image\", \"label\"],\n",
    "            prob=0.15,\n",
    "            spatial_size=(64, 64, 64),\n",
    "            rotate_range=[30 * np.pi / 180] * 3,\n",
    "            scale_range=[0.3] * 3,\n",
    "            mode=(\"bilinear\", \"bilinear\"),\n",
    "            as_tensor_output=False,\n",
    "        ),\n",
    "        transforms.RandFlipd([\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "        transforms.RandFlipd([\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "        transforms.RandFlipd([\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "        transforms.RandGaussianNoised(\"image\", prob=0.15, std=0.1),\n",
    "        transforms.RandGaussianSmoothd(\n",
    "            \"image\",\n",
    "            prob=0.15,\n",
    "            sigma_x=(0.5, 1.5),\n",
    "            sigma_y=(0.5, 1.5),\n",
    "            sigma_z=(0.5, 1.5),\n",
    "        ),\n",
    "        transforms.RandScaleIntensityd(\"image\", prob=0.15, factors=0.3),\n",
    "        transforms.RandShiftIntensityd(\"image\", prob=0.15, offsets=0.1),\n",
    "        transforms.RandAdjustContrastd(\"image\", prob=0.15, gamma=(0.7, 1.5)),\n",
    "        transforms.AsDiscreted(\"label\", threshold=0.5),\n",
    "        transforms.ToTensord([\"image\", \"label\"]),\n",
    "\n",
    "        Renamed(),\n",
    "    ]\n",
    "    train_transform = transforms.Compose(train_transform)\n",
    "    return train_transform\n",
    "\n",
    "\n",
    "def get_val_transform():\n",
    "    val_transform = [\n",
    "        ft.ReadImaged(\n",
    "            [\"image\", \"label\"], ensure_channel_first=True, allow_missing_keys=True\n",
    "        ),\n",
    "        transforms.SqueezeDimd(\"image\", dim=1),\n",
    "        transforms.NormalizeIntensityd(\"image\", nonzero=True, channel_wise=True),\n",
    "        transforms.ToTensord([\"image\", \"label\"], allow_missing_keys=True),\n",
    "\n",
    "        Renamed(),\n",
    "    ]\n",
    "    val_transform = transforms.Compose(val_transform)\n",
    "    return val_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff70f31-e0f5-4202-ba5a-f19c3bff644c",
   "metadata": {},
   "source": [
    "## Registry & Read config function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "458a1dce-a704-4607-a2fe-ad501ddfb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from torch import nn, optim\n",
    "import pytorch_lightning as pl\n",
    "import monai\n",
    "import factorizer as ft\n",
    "\n",
    "def lambda_constructor(loader, node):\n",
    "    lambda_expr = \"lambda \" + loader.construct_scalar(node)\n",
    "    return eval(lambda_expr)\n",
    "\n",
    "\n",
    "def get_constructor(obj):\n",
    "    \"\"\"Get constructor for an object.\"\"\"\n",
    "\n",
    "    def constructor(loader, node):\n",
    "        if isinstance(node, yaml.nodes.ScalarNode):\n",
    "            if node.value:\n",
    "                out = obj(loader.construct_scalar(node))\n",
    "            else:\n",
    "                out = obj\n",
    "        elif isinstance(node, yaml.nodes.SequenceNode):\n",
    "            out = obj(*loader.construct_sequence(node, deep=True))\n",
    "        elif isinstance(node, yaml.nodes.MappingNode):\n",
    "            out = obj(**loader.construct_mapping(node, deep=True))\n",
    "\n",
    "        return out\n",
    "\n",
    "    return constructor\n",
    "\n",
    "\n",
    "def add_attributes(obj, prefix=\"\"):\n",
    "    for attr_name in dir(obj):\n",
    "        if not attr_name.startswith(\"_\"):\n",
    "            Loader.add_constructor(\n",
    "                f\"!{prefix}{attr_name}\",\n",
    "                get_constructor(getattr(obj, attr_name)),\n",
    "            )\n",
    "\n",
    "\n",
    "Loader = yaml.SafeLoader\n",
    "\n",
    "\n",
    "# general\n",
    "Loader.add_constructor(\"!eval\", get_constructor(eval))\n",
    "Loader.add_constructor(\"!lambda\", lambda_constructor)\n",
    "\n",
    "\n",
    "# pytorch\n",
    "add_attributes(nn, \"nn.\")\n",
    "add_attributes(optim, \"optim.\")\n",
    "\n",
    "\n",
    "# pytorch lightning\n",
    "add_attributes(pl.callbacks, \"pl.\")\n",
    "add_attributes(pl.loggers, \"pl.\")\n",
    "\n",
    "\n",
    "# monai\n",
    "add_attributes(monai.losses, \"monai.\")\n",
    "add_attributes(monai.networks.nets, \"monai.\")\n",
    "\n",
    "\n",
    "# factorizer\n",
    "add_attributes(ft, \"ft.\")\n",
    "\n",
    "\n",
    "def read_config(path, loader=Loader):\n",
    "    with open(path, \"rb\") as file:\n",
    "        config = yaml.load(file, loader)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cda03-8b1d-4faa-9556-885d5ec3b7d6",
   "metadata": {},
   "source": [
    "## Quick checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6754be30-a05b-4a81-89a1-be1df55af35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft.ISLESDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd382267-246e-4493-a2e8-87fa11901f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.1'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b44efc11-ebca-48a1-b336-d5a480f8430d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa530b61-529e-4b9e-a8cf-e9c6335a3dbe",
   "metadata": {},
   "source": [
    "## Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e1914a40-1b0e-4f05-b5a8-6884d5b8cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import Dataset, DataLoader\n",
    "\n",
    "class ISLESDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_properties,\n",
    "        fold=0,\n",
    "        batch_size=2,\n",
    "        num_workers=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_properties = ft.load_properties(data_properties)\n",
    "        self.fold = fold\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.dataset_kwargs = kwargs\n",
    "\n",
    "        self.train_transform = get_train_transform()\n",
    "        self.val_transform = get_val_transform()\n",
    "        self.test_transform = get_val_transform()\n",
    "\n",
    "        self.train_set = self.val_set = self.test_set = None\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage in (\"fit\", \"validate\", None):\n",
    "            # make training set\n",
    "            training_data = []\n",
    "            val_data = []\n",
    "            for sample in self.data_properties[\"training\"]:\n",
    "                if sample[\"fold\"] == self.fold:\n",
    "                    val_data.append(sample)\n",
    "                else:\n",
    "                    training_data.append(sample)\n",
    "\n",
    "            self.train_set = Dataset(\n",
    "                training_data,\n",
    "                transform=self.train_transform,\n",
    "                **self.dataset_kwargs,\n",
    "            )\n",
    "            self.val_set = Dataset(\n",
    "                val_data,\n",
    "                transform=self.val_transform,\n",
    "                **self.dataset_kwargs,\n",
    "            )\n",
    "\n",
    "        if stage in (\"test\", \"predict\", None):\n",
    "            # make test set\n",
    "            self.test_set = Dataset(\n",
    "                self.data_properties[\"test\"],\n",
    "                transform=self.test_transform,\n",
    "                **self.dataset_kwargs,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.train_set,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(\n",
    "            self.val_set,\n",
    "            batch_size=1,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_loader = DataLoader(\n",
    "            self.test_set,\n",
    "            batch_size=1,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "968c32c9-13d7-44ad-a674-d7919c33dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ISLESDataModule(data_properties = \"/Data/data/isles/dataset_without_flair.json\", fold=1,\n",
    "        batch_size=2,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c76a53cd-484c-4c4d-8f55-d238451c98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<monai.data.dataset.Dataset object at 0x7f155de47190>\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup()\n",
    "print(datamodule.train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b9cde3c0-2ac9-4935-8f7a-d839b0f24960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(datamodule.train_dataloader()))\n",
    "# print(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e3e34-c14b-4bf0-8afa-a281b40b67ef",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877b4fa-a16d-46ea-a9df-3437c9cf30e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type                   | Params\n",
      "------------------------------------------------\n",
      "0 | net  | SegmentationFactorizer | 7.4 M \n",
      "1 | loss | DeepSuprLoss           | 0     \n",
      "------------------------------------------------\n",
      "7.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 M     Total params\n",
      "29.486    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e23b24e45764d98a37361dbdce1c23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551c818459c049a9a03526f1a1b9a608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from argparse import ArgumentParser, Namespace\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "# get config\n",
    "# parser = ArgumentParser(description=\"\"\"Train the model.\"\"\", add_help=False)\n",
    "# parser.add_argument(\"--config\", type=str, required=True)\n",
    "# args = parser.parse_args()\n",
    "path_config = \"/users/eleves-a/2022/oussama.zouhry/factorizer-project/image-segmentation-factorizer/factorizer/configs/isles2022-dwi&adc/config_isles2022-dwi&adc_fold0_swin-factorizer.yaml\"\n",
    "config = read_config(path_config)\n",
    "\n",
    "# data\n",
    "# dm = config[\"data\"]\n",
    "\n",
    "# init model\n",
    "task_cls, task_params = config[\"task\"]\n",
    "if \"checkpoint_path\" in task_params:\n",
    "    model = task_cls.load_from_checkpoint(strict=False, **task_params)\n",
    "else:\n",
    "    model = task_cls(**task_params)\n",
    "\n",
    "# init trainer\n",
    "trainer = Trainer(**config[\"training\"])\n",
    "\n",
    "# fit model\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e5c0d-2cf3-49a8-8b18-584bc0ee377b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
