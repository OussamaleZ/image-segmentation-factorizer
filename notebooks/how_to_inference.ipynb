{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236ca114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import factorizer as ft\n",
    "from monai import transforms\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af372204-724e-486a-a617-e7521a75b869",
   "metadata": {},
   "source": [
    "### Inference on ISLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ba18cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SemanticSegmentation(\n",
       "  (net): SegmentationFactorizer(\n",
       "    (stem): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (encoder): UNetEncoder(\n",
       "      (blocks): ModuleList(\n",
       "        (0): UNetEncoderBlock(\n",
       "          (blocks): Sequential(\n",
       "            (0): FactorizerBlock(\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=8, d=4, g0=16, p0=4, g1=16, p1=4, g2=16, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): UNetEncoderBlock(\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "            (1): FactorizerBlock(\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=16, d=4, g0=8, p0=4, g1=8, p1=4, g2=8, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): UNetEncoderBlock(\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "            (1): FactorizerBlock(\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=32, d=4, g0=4, p0=4, g1=4, p1=4, g2=4, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): UNetEncoderBlock(\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv3d(128, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "            (1): FactorizerBlock(\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=64, d=4, g0=2, p0=4, g1=2, p1=4, g2=2, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): UNetEncoderBlock(\n",
       "          (blocks): Sequential(\n",
       "            (0): Conv3d(256, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "            (1): FactorizerBlock(\n",
       "              (pos_embed): PosEmbed(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=128, d=4, g0=1, p0=4, g1=1, p1=4, g2=1, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): UNetDecoder(\n",
       "      (blocks): ModuleList(\n",
       "        (0): UNetDecoderBlock(\n",
       "          (upsample): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (blocks): Sequential(\n",
       "            (0): FactorizerBlock(\n",
       "              (adapter): Sequential(\n",
       "                (0): Linear(\n",
       "                  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                  (linear): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                )\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=64, d=4, g0=2, p0=4, g1=2, p1=4, g2=2, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): UNetDecoderBlock(\n",
       "          (upsample): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (blocks): Sequential(\n",
       "            (0): FactorizerBlock(\n",
       "              (adapter): Sequential(\n",
       "                (0): Linear(\n",
       "                  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                  (linear): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                )\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=32, d=4, g0=4, p0=4, g1=4, p1=4, g2=4, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): UNetDecoderBlock(\n",
       "          (upsample): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (blocks): Sequential(\n",
       "            (0): FactorizerBlock(\n",
       "              (adapter): Sequential(\n",
       "                (0): Linear(\n",
       "                  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                  (linear): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                )\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=16, d=4, g0=8, p0=4, g1=8, p1=4, g2=8, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): UNetDecoderBlock(\n",
       "          (upsample): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          (blocks): Sequential(\n",
       "            (0): FactorizerBlock(\n",
       "              (adapter): Sequential(\n",
       "                (0): Linear(\n",
       "                  (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                  (linear): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                )\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (blocks): ModuleDict(\n",
       "                (nmf): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): FactorizerSubblock(\n",
       "                      (in_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "                      )\n",
       "                      (tensorize): SWMatricize(\n",
       "                        (shifted_windows): ModuleList(\n",
       "                          (0-1): 2 x Matricize(\n",
       "                            (rearrange): Rearrange('b (h d) (g0 p0) (g1 p1) (g2 p2) -> (b h) (g0 g1 g2) d (p0 p1 p2)', d=4, p0=4, p1=4, p2=4)\n",
       "                            (rearrange_inv): Rearrange('(b h) (g0 g1 g2) d (p0 p1 p2) -> b (h d) (g0 p0) (g1 p1) (g2 p2)', h=8, d=4, g0=16, p0=4, g1=16, p1=4, g2=16, p2=4)\n",
       "                          )\n",
       "                        )\n",
       "                      )\n",
       "                      (act): ReLU()\n",
       "                      (factorize): NMF(\n",
       "                        (init): RandomInit()\n",
       "                        (solver): CoordinateDescent(\n",
       "                          (project): ReLU()\n",
       "                        )\n",
       "                      )\n",
       "                      (out_proj): Linear(\n",
       "                        (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                        (linear): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (mlp): Residual(\n",
       "                  (fn): Sequential(\n",
       "                    (0): LayerNorm(\n",
       "                      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                    )\n",
       "                    (1): MLP(\n",
       "                      (block): Sequential(\n",
       "                        (0): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (1): GELU(approximate='none')\n",
       "                        (2): Dropout(p=0.1, inplace=False)\n",
       "                        (3): Linear(\n",
       "                          (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "                          (linear): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "                        )\n",
       "                        (4): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (heads): ModuleList(\n",
       "      (0): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (2): Conv3d(128, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (loss): DeepSuprLoss(\n",
       "    (loss): DiceCELoss(\n",
       "      (dice): DiceLoss()\n",
       "      (cross_entropy): CrossEntropyLoss()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the weights into the model\n",
    "checkpoint_root = Path(\"/Data/logs/isles2022-dwi&adc/fold0/image-segmentation-factorizer/51ij4wr5/checkpoints/epoch=999-step=100000.ckpt\")\n",
    "model = ft.SemanticSegmentation.load_from_checkpoint(checkpoint_root).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ec4d6-ebe3-460a-89aa-fab2dca10660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datamodule\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "\n",
    "# Rebuild dm for the full dataset using the JSON properties file\n",
    "dm = ft.ISLESDataModule(\n",
    "    data_properties=\"/Data/data/isles/dataset_without_flair.json\",\n",
    "    spacing=[2.0, 2.0, 2.0],\n",
    "    spatial_size=[64, 64, 64],\n",
    "    num_workers=24,\n",
    "    cache_num=4,\n",
    "    cache_rate=1.0,\n",
    "    batch_size=1,\n",
    "    seed=42,\n",
    ")\n",
    "dm.test_transform = transforms.Compose([\n",
    "    ft.ReadImaged(['input', 'label'], allow_missing_keys=False),\n",
    "    transforms.NormalizeIntensityd('input', nonzero=True, channel_wise=True),\n",
    "    transforms.ToTensord(['input', 'label']),\n",
    "])\n",
    "dm.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "804c1c47-bbea-4de6-a88a-bded7a392b6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the data to aggregate must be PyTorch Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(pred))\n\u001b[1;32m     18\u001b[0m         dice_metric(\n\u001b[1;32m     19\u001b[0m             y_pred\u001b[38;5;241m=\u001b[39mpost_pred(pred[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     20\u001b[0m             y\u001b[38;5;241m=\u001b[39mpost_label(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     21\u001b[0m         )\n\u001b[0;32m---> 22\u001b[0m dice_scores \u001b[38;5;241m=\u001b[39m \u001b[43mdice_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean_batch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     23\u001b[0m dice_metric\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Dice (mean):\u001b[39m\u001b[38;5;124m\"\u001b[39m, dice_scores\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/factorizer-project/image-segmentation-factorizer/factorizer-env3.9/lib64/python3.9/site-packages/monai/metrics/meandice.py:97\u001b[0m, in \u001b[0;36mDiceMetric.aggregate\u001b[0;34m(self, reduction)\u001b[0m\n\u001b[1;32m     95\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_buffer()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe data to aggregate must be PyTorch Tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# do metric reduction\u001b[39;00m\n\u001b[1;32m    100\u001b[0m f, not_nans \u001b[38;5;241m=\u001b[39m do_metric_reduction(data, reduction \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
      "\u001b[0;31mValueError\u001b[0m: the data to aggregate must be PyTorch Tensor."
     ]
    }
   ],
   "source": [
    "# Metric and postprocessing\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "post_pred = AsDiscrete(threshold=0.5)\n",
    "post_label = AsDiscrete(threshold=0.5)\n",
    "\n",
    "model.eval()\n",
    "dice_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dm.test_dataloader():\n",
    "        batch['input'] = batch['input'].to(device)\n",
    "        batch['label'] = batch['label'].to(device)\n",
    "        pred = model.inferer.get_postprocessed(batch, model)\n",
    "        print(5)\n",
    "        print(type(pred))\n",
    "        \n",
    "        dice_metric(\n",
    "            y_pred=post_pred(pred['input']),\n",
    "            y=post_label(batch['label']),\n",
    "        )\n",
    "        \n",
    "dice_scores = dice_metric.aggregate(reduction=\"mean_batch\").cpu().numpy()\n",
    "dice_metric.reset()\n",
    "\n",
    "print(\"Dataset Dice (mean):\", dice_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6842a-daf4-4e5d-a982-1bd4e27e349a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factorizer-env3.9 (3.9.23)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
